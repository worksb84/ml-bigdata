{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions._\n",
    "import scala.util.{Failure, Success, Try}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "import java.time.LocalDateTime\n",
    "import java.time.LocalDate\n",
    "import java.time.format.DateTimeFormatter\n",
    "import java.time.temporal.ChronoUnit.DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateTimeFormatter = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\")\n",
    "def appName: String = LocalDateTime.now().format(dateTimeFormatter)\n",
    "def previousDay(minusDays: Long) = {\n",
    "    LocalDateTime.now().minusDays(minusDays).format(dateTimeFormatter).substring(0, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val appName = LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"))\n",
    "\n",
    "val spark = (\n",
    "    SparkSession\n",
    "    .builder()\n",
    "    .appName(appName)\n",
    "    .config(\"spark.cores.max\", 8)\n",
    "    .config(\"spark.executor.cores\", 8)\n",
    "    .config(\"spark.executor.memory\", \"36g\")\n",
    "    .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val mongoUrl = \"mongodb+srv://xxxxxxxxxxxxxxxxxxxxxx/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fsDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"ReportRiskPremiumWithPbrPerStress\")\n",
    "    .load()\n",
    "    .drop(\"_id\")\n",
    "    .withColumnRenamed(\"riskPremium\", \"FSRiskPremium\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val nsDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"NewsRiskPremium\")\n",
    "    .load()\n",
    "    .drop(\"_id\", \"riskParagraph\", \"wholeParagraph\")\n",
    "    .withColumnRenamed(\"riskPremium\", \"NSRiskPremium\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val hfDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"aggregation.pipeline\", \"{ $match: { updateDate: { $gte: '20230401' } } }\")\n",
    "    .option(\"collection\", \"PriceRiskPremium\")\n",
    "    .load()\n",
    "    .drop(\"_id\", \"stockFullName\")\n",
    "    .withColumnRenamed(\"riskPremium\", \"HFRiskPremium\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val indexDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"IndexComposition\")\n",
    "    .option(\"aggregation.pipeline\", \"{ $match: { updateDate: { $gte: '20230401' } } }\")\n",
    "    .load()\n",
    "    .select(\"updateDate\", \"rank\", \"index\", \"isuSrtCd\")\n",
    "    .withColumnRenamed(\"isuSrtCd\", \"stockCode\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val prDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"Price\")\n",
    "    .option(\"aggregation.pipeline\", \"{ $match: { updateDate: { $gte: '20230401' } } }\")\n",
    "    .load()\n",
    "    .select(\"stockCode\", \"updateDate\", \"classify\")\n",
    "    .withColumn(\"classify\", when(col(\"classify\") === \"KOSPI\", \"Y\").otherwise(\"K\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val kosdaq150Df = indexDf.where(col(\"index\") === \"kosdaq_150\").withColumnRenamed(\"rank\", \"kosdaq150\").drop(\"rank\").drop(\"index\")\n",
    "val kospi200Df = indexDf.where(col(\"index\") === \"kospi_200\").withColumnRenamed(\"rank\", \"kospi200\").drop(\"rank\").drop(\"index\")\n",
    "val krx100Df = indexDf.where(col(\"index\") === \"krx_100\").withColumnRenamed(\"rank\", \"krx100\").drop(\"rank\").drop(\"index\")\n",
    "val krx300Df = indexDf.where(col(\"index\") === \"krx_300\").withColumnRenamed(\"rank\", \"krx300\").drop(\"rank\").drop(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// fsDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val partition = Window.partitionBy(\"stockCode\").orderBy(\"updateDate\")\n",
    "val ff = partition.rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "val rpdf = (\n",
    "    hfDf\n",
    "    .join(fsDf, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(nsDf, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .withColumn(\"stockCode\", last(col(\"stockCode\"), true).over(ff))\n",
    "    .withColumn(\"updateDate\", last(col(\"updateDate\"), true).over(ff))\n",
    "    .withColumn(\"HFRiskPremium\", last(col(\"HFRiskPremium\"), true).over(ff))\n",
    "    .withColumn(\"warningSignal\", last(col(\"warningSignal\"), true).over(ff))\n",
    "    .withColumn(\"FSPctRank\", last(col(\"FSPctRank\"), true).over(ff))\n",
    "    .withColumn(\"RegUpdateDate\", last(col(\"RegUpdateDate\"), true).over(ff))\n",
    "    .withColumn(\"TF1\", last(col(\"TF1\"), true).over(ff))\n",
    "    .withColumn(\"TF2\", last(col(\"TF2\"), true).over(ff))\n",
    "    .withColumn(\"TF3\", last(col(\"TF3\"), true).over(ff))\n",
    "    .withColumn(\"TT\", last(col(\"TT\"), true).over(ff))\n",
    "    .withColumn(\"VaRTF1\", last(col(\"VaRTF1\"), true).over(ff))\n",
    "    .withColumn(\"VaRTF2\", last(col(\"VaRTF2\"), true).over(ff))\n",
    "    .withColumn(\"VaRTF3\", last(col(\"VaRTF3\"), true).over(ff))\n",
    "    .withColumn(\"balanceRateLoan\", last(col(\"balanceRateLoan\"), true).over(ff))\n",
    "    .withColumn(\"basicReturn\", last(col(\"basicReturn\"), true).over(ff))\n",
    "    .withColumn(\"bsnsYear\", last(col(\"bsnsYear\"), true).over(ff))\n",
    "    .withColumn(\"corpCls\", last(col(\"corpCls\"), true).over(ff))\n",
    "    .withColumn(\"corpCode\", last(col(\"corpCode\"), true).over(ff))\n",
    "    .withColumn(\"event\", last(col(\"event\"), true).over(ff))\n",
    "    .withColumn(\"expectedLossFN1\", last(col(\"expectedLossFN1\"), true).over(ff))\n",
    "    .withColumn(\"expectedLossFN2\", last(col(\"expectedLossFN2\"), true).over(ff))\n",
    "    .withColumn(\"expectedLossFN3\", last(col(\"expectedLossFN3\"), true).over(ff))\n",
    "    .withColumn(\"expectedProfit\", last(col(\"expectedProfit\"), true).over(ff))\n",
    "    .withColumn(\"expectedRisk\", last(col(\"expectedRisk\"), true).over(ff))\n",
    "    .withColumn(\"fixed_pbr\", last(col(\"fixed_pbr\"), true).over(ff))\n",
    "    .withColumn(\"fixed_per\", last(col(\"fixed_per\"), true).over(ff))\n",
    "    .withColumn(\"grade\", last(col(\"grade\"), true).over(ff))\n",
    "    .withColumn(\"hfrp\", last(col(\"hfrp\"), true).over(ff))\n",
    "    .withColumn(\"loanAvailable\", last(col(\"loanAvailable\"), true).over(ff))\n",
    "    .withColumn(\"lockAlert30\", last(col(\"lockAlert30\"), true).over(ff))\n",
    "    .withColumn(\"lockAlert60\", last(col(\"lockAlert60\"), true).over(ff))\n",
    "    .withColumn(\"lockWarn30\", last(col(\"lockWarn30\"), true).over(ff))\n",
    "    .withColumn(\"lockWarn60\", last(col(\"lockWarn60\"), true).over(ff))\n",
    "    .withColumn(\"marketCap\", last(col(\"marketCap\"), true).over(ff))\n",
    "    .withColumn(\"pbr\", last(col(\"pbr\"), true).over(ff))\n",
    "    .withColumn(\"per\", last(col(\"per\"), true).over(ff))\n",
    "    .withColumn(\"plbtEvent\", last(col(\"plbtEvent\"), true).over(ff))\n",
    "    .withColumn(\"predict\", last(col(\"predict\"), true).over(ff))\n",
    "    .withColumn(\"priceEvent\", last(col(\"priceEvent\"), true).over(ff))\n",
    "    .withColumn(\"profitLoss\", last(col(\"profitLoss\"), true).over(ff))\n",
    "    .withColumn(\"quarter\", last(col(\"quarter\"), true).over(ff))\n",
    "    .withColumn(\"r\", last(col(\"r\"), true).over(ff))\n",
    "    .withColumn(\"r_s\", last(col(\"r_s\"), true).over(ff))\n",
    "    .withColumn(\"rank\", last(col(\"rank\"), true).over(ff))\n",
    "    .withColumn(\"rceptNo\", last(col(\"rceptNo\"), true).over(ff))\n",
    "    .withColumn(\"reGrade\", last(col(\"reGrade\"), true).over(ff))\n",
    "    .withColumn(\"reLoanAvailable\", last(col(\"reLoanAvailable\"), true).over(ff))\n",
    "    .withColumn(\"rePredict\", last(col(\"rePredict\"), true).over(ff))\n",
    "    .withColumn(\"reRank\", last(col(\"reRank\"), true).over(ff))\n",
    "    .withColumn(\"recoveryFN1\", last(col(\"recoveryFN1\"), true).over(ff))\n",
    "    .withColumn(\"recoveryFN2\", last(col(\"recoveryFN2\"), true).over(ff))\n",
    "    .withColumn(\"recoveryFN3\", last(col(\"recoveryFN3\"), true).over(ff))\n",
    "    .withColumn(\"reprtCode\", last(col(\"reprtCode\"), true).over(ff))\n",
    "    .withColumn(\"FSRiskPremium\", last(col(\"FSRiskPremium\"), true).over(ff))\n",
    "    .withColumn(\"stockName\", last(col(\"stockName\"), true).over(ff))\n",
    "    .withColumn(\"stress\", last(col(\"stress\"), true).over(ff))\n",
    "    .withColumn(\"stressAlert\", last(col(\"stressAlert\"), true).over(ff))\n",
    "    .withColumn(\"stressWarn\", last(col(\"stressWarn\"), true).over(ff))\n",
    "    .withColumn(\"threshold\", last(col(\"threshold\"), true).over(ff))\n",
    "    .withColumn(\"documentRiskPremium\", last(col(\"documentRiskPremium\"), true).over(ff))\n",
    "    .withColumn(\"NSRiskPremium\", last(col(\"NSRiskPremium\"), true).over(ff))\n",
    "    .where(col(\"FSPctRank\").isNotNull)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val vixDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"KospiVolatilityCalcurate\")\n",
    "    .load()\n",
    "    .drop(\"_id\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val riskPremiumDf = (\n",
    "    rpdf\n",
    "    .na.fill(0)\n",
    "    .join(vixDf, Seq(\"updateDate\"), \"left\")\n",
    "    .withColumn(\"BDRiskPremium\", lit(0))\n",
    "    .withColumn(\"FNRiskPremium\", lit(0))\n",
    "    .withColumn(\"HFPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"HFRiskPremium\")))\n",
    "    .withColumn(\"BDPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"BDRiskPremium\")))\n",
    "    .withColumn(\"FNPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"FNRiskPremium\")))\n",
    "    .withColumn(\"NSPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"NSRiskPremium\")))\n",
    "    .withColumn(\"riskPremium\", col(\"FSRiskPremium\") + (col(\"HFRiskPremium\") * lit(0.0001)) + (col(\"BDRiskPremium\") * lit(0.0001)) + (col(\"FNRiskPremium\") * lit(0.0001)) + (col(\"NSRiskPremium\") * lit(0.0001)))\n",
    "    .withColumn(\"prevRiskPremium\", lag(col(\"riskPremium\"), 1).over(Window.partitionBy(\"stockCode\").orderBy(\"updateDate\")))\n",
    "    .withColumn(\"diffRiskPremium\", col(\"riskPremium\") - col(\"prevRiskPremium\"))\n",
    "    .withColumn(\"score\", ((lit(1) - col(\"FSPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"FSScore\", ((lit(1) - col(\"FSPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"HFScore\", ((lit(1) - col(\"HFPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"BDScore\", ((lit(1) - col(\"BDPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"FNScore\", ((lit(1) - col(\"FNPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"NSScore\", ((lit(1) - col(\"NSPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"ReRank\", col(\"reRank\"))\n",
    "    .withColumn(\"loanThreshold\", sum(when(col(\"grade\") === \"A\" or col(\"grade\") === \"B\" or col(\"grade\") === \"C\", 1).otherwise(0)).over(Window.partitionBy(col(\"updateDate\"))) * col(\"volatilityThreshold\"))\n",
    "    .withColumn(\"creditLoanAvailable\", when(col(\"reRank\") < col(\"loanThreshold\"), 1).otherwise(0))\n",
    "    .join(kosdaq150Df, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(kospi200Df, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(krx100Df, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(krx300Df, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .withColumn(\"fs\", struct(col(\"FSRiskPremium\").as(\"riskPremium\"), col(\"FSScore\").as(\"score\")))\n",
    "    .withColumn(\"hf\", struct(col(\"HFRiskPremium\").as(\"riskPremium\"), col(\"HFScore\").as(\"score\")))\n",
    "    .withColumn(\"bd\", struct(col(\"BDRiskPremium\").as(\"riskPremium\"), col(\"BDScore\").as(\"score\")))\n",
    "    .withColumn(\"fn\", struct(col(\"FNRiskPremium\").as(\"riskPremium\"), col(\"FNScore\").as(\"score\")))\n",
    "    .withColumn(\"ns\", struct(col(\"NSRiskPremium\").as(\"riskPremium\"), col(\"NSScore\").as(\"score\")))\n",
    "    .withColumn(\"detail\", struct(col(\"fs\"), col(\"hf\"), col(\"bd\"), col(\"fn\"), col(\"ns\")))\n",
    "    .withColumn(\"rank\", struct(col(\"ReRank\"), col(\"kosdaq150\"), col(\"kospi200\"), col(\"krx100\"), col(\"krx300\")))\n",
    "    .join(prDf, Seq(\"updateDate\", \"stockCode\"), \"left\")\n",
    "    .drop(\"corpCls\")\n",
    "    .withColumnRenamed(\"classify\", \"corpCls\")\n",
    "    .select(\n",
    "        \"corpCls\", \"stockCode\", \"updateDate\", \"grade\", \"reGrade\", \"loanThreshold\", \"stockName\", \"riskPremium\", \n",
    "        \"prevRiskPremium\", \"diffRiskPremium\", \"score\", \"detail\", \"rank\", \"reRank\", \"loanAvailable\", \"reLoanAvailable\", \"creditLoanAvailable\", \n",
    "        \"VaRTF1\", \"VaRTF2\", \"VaRTF3\", \"basicReturn\", \"expectedProfit\", \"expectedRisk\", \"profitLoss\",\n",
    "        \"fixed_pbr\", \"fixed_per\", \"lockAlert30\", \"lockAlert60\", \"lockWarn30\", \"lockWarn60\", \"pbr\", \"per\", \"plbtEvent\", \"stressAlert\", \"stressWarn\",\n",
    "        \"priceEvent\", \"stress\", \"balanceRateLoan\"\n",
    "    )\n",
    ")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(\n",
    "    riskPremiumDf\n",
    "    .where(col(\"updateDate\") > \"20230630\")\n",
    "    .write.format(\"mongodb\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"upsertDocument\", \"true\")\n",
    "    .option(\"idFieldList\", \"updateDate,stockCode\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"RiskPremium_New\")\n",
    "    .save()\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
