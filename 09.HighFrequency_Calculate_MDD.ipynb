{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions._\n",
    "import scala.util.{Failure, Success, Try}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val spark = (\n",
    "    SparkSession\n",
    "    .builder()\n",
    "    .appName(\"MDD\")\n",
    "    .config(\"spark.cores.max\", 4)\n",
    "    .config(\"spark.executor.cores\", 4)\n",
    "    .config(\"spark.executor.memory\", \"36g\")\n",
    "    .getOrCreate()\n",
    "    )\n",
    "    \n",
    "val csv_options = Map(\"header\" -> \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val mongoUrl = \"mongodb+srv://xxxxxxxxxxxxxxxxxxxxxx/\"\n",
    "\n",
    "val stockPrice = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"aggregation.pipeline\", \"{ $match: { updateDate: { $gte: '20230101'} } }\")\n",
    "    .option(\"collection\", \"Price\").load()\n",
    "    .withColumn(\"closingPrice\",col(\"closingPrice\").cast(IntegerType))\n",
    "    .withColumn(\"market\", when(col(\"classify\") === \"KOSDAQ\", 0).otherwise(1))\n",
    "    .select(\"stockCode\", \"stockFullName\", \"market\", \"closingPrice\", \"updateDate\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val partition = Window.partitionBy(\"stockCode\").orderBy(\"updateDate\")\n",
    "val w_5 = partition.rowsBetween(-5, 0)\n",
    "val w_22 = partition.rowsBetween(-22, 0)\n",
    "val w_65 = partition.rowsBetween(-65, 0)\n",
    "val w_126 = partition.rowsBetween(-126, 0)\n",
    "\n",
    "val mdd = (\n",
    "    stockPrice\n",
    "    .withColumn(\"max5Price\", max(col(\"closingPrice\")).over(w_5))\n",
    "    .withColumn(\"min5Price\", min(col(\"closingPrice\")).over(w_5))\n",
    "    .withColumn(\"mdd5Days\", (col(\"min5Price\") - col(\"max5Price\")) / col(\"max5Price\"))\n",
    "    .withColumn(\"max22Price\", max(col(\"closingPrice\")).over(w_22))\n",
    "    .withColumn(\"min22Price\", min(col(\"closingPrice\")).over(w_22))\n",
    "    .withColumn(\"mdd22Days\", (col(\"min22Price\") - col(\"max22Price\")) / col(\"max22Price\"))\n",
    "    .withColumn(\"max65Price\", max(col(\"closingPrice\")).over(w_65))\n",
    "    .withColumn(\"min65Price\", min(col(\"closingPrice\")).over(w_65))\n",
    "    .withColumn(\"mdd65Days\", (col(\"min65Price\") - col(\"max65Price\")) / col(\"max65Price\"))\n",
    "    .withColumn(\"max126Price\", max(col(\"closingPrice\")).over(w_126))\n",
    "    .withColumn(\"min126Price\", min(col(\"closingPrice\")).over(w_126))\n",
    "    .withColumn(\"mdd126Days\", (col(\"min126Price\") - col(\"max126Price\")) / col(\"max126Price\"))\n",
    "    .where(col(\"updateDate\") > \"20230630\")\n",
    "    .where((col(\"mdd5Days\").isNotNull) and (col(\"mdd22Days\").isNotNull) and (col(\"mdd65Days\").isNotNull))\n",
    "    .select(\"stockCode\", \"stockFullName\", \"market\", \"closingPrice\", \"updateDate\", \"mdd5Days\", \"mdd22Days\", \"mdd65Days\", \"mdd126Days\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(\n",
    "    mdd.where(col(\"updateDate\") > \"20230630\")\n",
    "    .write.format(\"mongodb\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"upsertDocument\", \"true\")\n",
    "    .option(\"idFieldList\", \"updateDate,stockCode\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"PriceMDDCalcurate\")\n",
    "    .save()\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
