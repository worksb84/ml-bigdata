{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions._\n",
    "import scala.util.{Failure, Success, Try}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import com.mongodb.spark._\n",
    "import com.mongodb.spark.config._\n",
    "import org.bson._\n",
    "\n",
    "import java.time.LocalDateTime\n",
    "import java.time.LocalDate\n",
    "import java.time.format.DateTimeFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val spark = (\n",
    "    SparkSession\n",
    "    .builder()\n",
    "    .appName(\"Frequency\")\n",
    "    .config(\"spark.cores.max\", 6)\n",
    "    .config(\"spark.executor.cores\", 6)\n",
    "    .config(\"spark.executor.memory\", \"36g\")\n",
    "    .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateTimeFormatter = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\")\n",
    "def appName: String = LocalDateTime.now().format(dateTimeFormatter)\n",
    "def previousDay(minusDays: Long) = {\n",
    "    LocalDateTime.now().minusDays(minusDays).format(dateTimeFormatter).substring(0, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// val df = (\n",
    "//     spark.read.format(\"mongodb\")\n",
    "//     .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "//     .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "//     .option(\"database\", \"coreEngine\")\n",
    "//     .option(\"collection\", \"Price\").load()\n",
    "//     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val mongoUrl = \"mongodb+srv://xxxxxxxxxxxxxxxxxxxxxx/\"\n",
    "\n",
    "val priceReadConfig = ReadConfig(Map(\n",
    "  \"spark.mongodb.input.uri\" -> mongoUrl,\n",
    "  \"spark.mongodb.input.database\" -> \"coreEngine\",\n",
    "  \"spark.mongodb.input.collection\" -> \"Price\",\n",
    "))\n",
    "\n",
    "val priceWriteConfig = WriteConfig(Map(\n",
    "  \"spark.mongodb.output.uri\" -> mongoUrl,\n",
    "  \"spark.mongodb.output.database\" -> \"coreEngine\",\n",
    "  \"spark.mongodb.output.collection\" -> \"Price\",\n",
    "  \"spark.mongodb.output.maxBatchSize\" -> \"8000\"  \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val priceMatchPipe = String.format(\"{ $match: { updateDate: { $gte: '%s' } } }\", previousDay(2555))\n",
    "val rdd = MongoSpark.load(spark.sparkContext, priceReadConfig)\n",
    "val priceDf = rdd.withPipeline(Seq(Document.parse(priceMatchPipe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val priceYFReadConfig = ReadConfig(Map(\n",
    "  \"spark.mongodb.input.uri\" -> mongoUrl,\n",
    "  \"spark.mongodb.input.database\" -> \"coreEngine\",\n",
    "  \"spark.mongodb.input.collection\" -> \"PriceYF\",\n",
    "))\n",
    "\n",
    "val priceYFWriteConfig = WriteConfig(Map(\n",
    "  \"spark.mongodb.output.uri\" -> mongoUrl,\n",
    "  \"spark.mongodb.output.database\" -> \"coreEngine\",\n",
    "  \"spark.mongodb.output.collection\" -> \"PriceYF\",\n",
    "  \"spark.mongodb.output.maxBatchSize\" -> \"8000\"  \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val priceYFMatchPipe = String.format(\"{ $match: { updateDate: { $gte: '%s' } } }\", previousDay(2555))\n",
    "val rdd = MongoSpark.load(spark.sparkContext, priceYFReadConfig)\n",
    "val priceYFDf = rdd.withPipeline(Seq(Document.parse(priceYFMatchPipe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val pdf = priceDf.toDF().drop(\"_id\")\n",
    "val pyfdf = priceYFDf.toDF().select(\"updateDate\", \"adjPrice\", \"stockCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val mergeDf = (\n",
    "    pdf.join(pyfdf, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .withColumn(\"closingPrice\", when(col(\"adjPrice\").isNull, col(\"adjPrice\")).otherwise(col(\"closingPrice\")))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val window = Window.partitionBy(col(\"stockCode\")).orderBy(col(\"updateDate\"))\n",
    "val rankWindow = Window.partitionBy(col(\"stockCode\")).orderBy(col(\"updateDate\").desc)\n",
    "val hf = (\n",
    "    mergeDf\n",
    "    .where(col(\"closingPrice\").isNotNull)\n",
    "    .withColumn(\"market\", when(col(\"classify\") === \"KOSDAQ\", 0).otherwise(1))\n",
    "    .select(\"stockCode\", \"stockFullName\", \"market\", \"closingPrice\", \"prepare\", \"openPrice\", \"highPrice\", \"lowPrice\", \"tradingVolume\", \"transactionAmount\", \"updateDate\")\n",
    "    .withColumn(\"closingPricePrev\", lag(col(\"closingPrice\"), 1).over(window))\n",
    "    .withColumn(\"closingPriceNext\", lag(col(\"closingPrice\"), -1).over(window))\n",
    "    .withColumn(\"closingPriceDiff\", col(\"closingPrice\") - col(\"closingPricePrev\"))\n",
    "    .withColumn(\"closingPriceReturn\", log(col(\"closingPrice\") / col(\"closingPricePrev\")))\n",
    "    .withColumn(\"closingPriceEvt\", when(col(\"closingPriceDiff\") <= (col(\"closingPricePrev\") * -0.1), 1).otherwise(0))\n",
    "    .withColumn(\"closingPrice5Min\", min(col(\"closingPriceDiff\")).over(window.rowsBetween(-4, 0)))\n",
    "    .withColumn(\"closingPrice5Max\", max(col(\"closingPriceDiff\")).over(window.rowsBetween(-4, 0)))\n",
    "    .withColumn(\"closingPrice5\", when((col(\"closingPrice5Max\").cast(\"long\") < 0) && (col(\"closingPrice5Min\").cast(LongType) < 0), 1).otherwise(0))\n",
    "    .withColumn(\"tradingVolumeLog\", log(col(\"tradingVolume\")))\n",
    "    .withColumn(\"closingPriceReturn5days\", mean(col(\"closingPriceReturn\")).over(window.rowsBetween(-4, 0)))\n",
    "    .withColumn(\"closingPriceReturn22days\", mean(col(\"closingPriceReturn\")).over(window.rowsBetween(-21, 0)))\n",
    "    .withColumn(\"tradingVolumeVolatility5days\", (variance(col(\"tradingVolume\")).over(window.rowsBetween(-4, 0))))\n",
    "    .withColumn(\"tradingVolumeVolatility22days\", (variance(col(\"tradingVolume\")).over(window.rowsBetween(-21, 0))))\n",
    "    .withColumn(\"tradingVolumeVolatility5daysLog\", log(col(\"tradingVolume\")))\n",
    "    .withColumn(\"tradingVolumeVolatility22daysLog\", log(col(\"tradingVolume\")))\n",
    "    .withColumn(\"event\", when((col(\"closingPriceEvt\") === 1) || (col(\"closingPrice5\") === 1), 1).otherwise(0))\n",
    "    .select(\"stockCode\", \"stockFullName\", \"market\", \"updateDate\", \"closingPrice\", \"tradingVolume\", \"transactionAmount\", \"closingPricePrev\", \"closingPriceNext\", \"closingPriceDiff\", \"closingPriceReturn\", \"closingPrice5Min\", \"closingPrice5Max\", \"closingPrice5\", \"tradingVolumeLog\", \"closingPriceReturn5days\", \"closingPriceReturn22days\", \"tradingVolumeVolatility5days\", \"tradingVolumeVolatility22days\", \"tradingVolumeVolatility5daysLog\", \"tradingVolumeVolatility22daysLog\", \"event\")\n",
    "//     .withColumn(\"rank\", row_number().over(rankWindow))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(\n",
    "    hf.where(col(\"updateDate\") === \"20230428\" and col(\"stockCode\") === \"005930\")\n",
    "    .na.fill(0)\n",
    "    .write.format(\"mongodb\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"upsertDocument\", \"true\")\n",
    "    .option(\"idFieldList\", \"updateDate,stockCode\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"PriceFeatures\")\n",
    "    .save()\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(\n",
    "    hf\n",
    "//     .where(col(\"rank\") === 1)\n",
    "//     .drop(\"rank\")\n",
    "//     .orderBy(col(\"stockCode\"), col(\"updateDate\"))\n",
    "    .na.fill(0)\n",
    "    .write.format(\"mongodb\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"PriceFeatures\")\n",
    "    .save()\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case class HighFrequencyModel(\n",
    "    stockCode: String,\n",
    "    stockFullName: String,\n",
    "    market: Int,\n",
    "    updateDate: String,\n",
    "    closingPrice: Int,\n",
    "    tradingVolume: Int,\n",
    "    transactionAmount: Long,\n",
    "    closingPricePrev: Int,\n",
    "    closingPriceNext: Int,\n",
    "    closingPriceDiff: Int,\n",
    "    closingPriceReturn: Double,\n",
    "    closingPrice5Min: Int,\n",
    "    closingPrice5Max: Int,\n",
    "    closingPrice5: Int,\n",
    "    tradingVolumeLog: Double,\n",
    "    closingPriceReturn5days: Double,\n",
    "    closingPriceReturn22days: Double,\n",
    "    tradingVolumeVolatility5days: Double,\n",
    "    tradingVolumeVolatility22days: Double,\n",
    "    tradingVolumeVolatility5daysLog: Double,\n",
    "    tradingVolumeVolatility22daysLog: Double,\n",
    "    event: Int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val result = hf.where(col(\"rank\") === 1).drop(\"rank\").orderBy(\"stockCode\").na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.as[HighFrequencyModel].collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
