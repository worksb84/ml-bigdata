{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.install_pypi_package(\"pybind11==2.10.3\")\n",
    "sc.install_pypi_package(\"numpy==1.19.0\")\n",
    "sc.install_pypi_package(\"Pillow==8.2\")\n",
    "sc.install_pypi_package(\"Cython==0.29.33\")\n",
    "sc.install_pypi_package(\"scipy==1.2.0\")\n",
    "sc.install_pypi_package(\"pythran==0.12.1\")\n",
    "sc.install_pypi_package(\"pandas==1.0.0\")\n",
    "sc.install_pypi_package(\"matplotlib==3.3.0\")\n",
    "sc.install_pypi_package(\"lifelines==0.27.4\")\n",
    "sc.install_pypi_package(\"s3fs==0.4.2\")\n",
    "sc.install_pypi_package(\"boto3==1.26.59\")\n",
    "sc.install_pypi_package(\"joblib==1.2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "import pickle\n",
    "import tempfile\n",
    "import joblib\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MongoUrl = \"mongodb+srv://xxxxxxxxxxxxxxxxxxxxxx/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"FinancialSheets_ML_Training\") \\\n",
    "    .config(\"spark.cores.max\", 4) \\\n",
    "    .config(\"spark.executor.cores\", 4) \\\n",
    "    .config(\"spark.executor.memory\", \"36g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongodb\") \\\n",
    "    .option(\"spark.mongodb.read.connection.uri\", MongoUrl) \\\n",
    "    .option(\"spark.mongodb.write.connection.uri\", MongoUrl) \\\n",
    "    .option(\"database\", \"coreEngine\") \\\n",
    "    .option(\"collection\", \"ReportFeatures\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historicalDay = df.select(\"updateDate\").distinct().orderBy(\"updateDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historicalDayList = [i[0] for i in historicalDay.toPandas().values if i[0] > '20180101']\n",
    "# 20180103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_features = features.drop([\"_id\"], axis=1)\n",
    "hf_features[\"event\"] = hf_features[\"event\"].fillna(0).astype(bool)\n",
    "hf_features = hf_features.sort_values([\"stockCode\", \"rceptNo\"])\n",
    "hf_features = hf_features[hf_features[\"period\"] >= 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"CACL\", \"CATA\", \"CLCA\", \"CLGR\", \"CLTL\", \"DSR01\", \"DSR02\", \"DSR03\", \n",
    "    \"DSR04\", \"DSR05\", \"DSR06\", \"DSR07\", \"EBTIN\", \"EQTA\", \"FAGR\", \n",
    "    \"FFOEQ\", \"FFOTL\", \"INSL\", \"INTL\", \"LNSL\", \"LNTA\", \"MB\", \"NEGBE\", \n",
    "    \"NIGR\", \"NISL\", \"RETA\", \"SLEQ\", \"SLFA\", \"TLEQ\", \"TLTA\"]\n",
    "\n",
    "for column in columns:\n",
    "    hf_features[column]=hf_features.groupby([\"bsnsYear\", \"reprtCode\"])[column].apply(lambda x:x.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_features = hf_features.fillna(0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for i in historicalDayList:\n",
    "    dfs.append(hf_features[hf_features[\"updateDate\"] <= i].sort_values(by=\"updateDate\", ascending=True).drop_duplicates().groupby(\"stockCode\").head(10000).sort_values(by=[\"stockCode\", \"updateDate\"], ascending=True).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    region_name=\"ap-northeast-2\",\n",
    "    aws_access_key_id=\"xxxxxxxxxxxxxxxxxxxxxx\",\n",
    "    aws_secret_access_key=\"xxxxxxxxxxxxxxxxxxxxxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, dfi in enumerate(dfs):\n",
    "    filterColumns = [\n",
    "        \"CACL\", \"CATA\", \"CLCA\", \"CLGR\", \"CLTL\", \"DSR01\", \"DSR02\", \"DSR03\", \n",
    "        \"DSR04\", \"DSR05\", \"DSR06\", \"DSR07\", \"EBTIN\", \"EQTA\", \"FAGR\", \n",
    "        \"FFOEQ\", \"FFOTL\", \"INSL\", \"INTL\", \"LNSL\", \"LNTA\", \"MB\", \"NEGBE\", \n",
    "        \"NIGR\", \"NISL\", \"RETA\", \"SLEQ\", \"SLFA\", \"TLEQ\", \"TLTA\", \"period\", \"event\"]\n",
    "    \n",
    "    model_name = historicalDayList[idx]\n",
    "\n",
    "    df_train_set = dfi.set_index([\"stockCode\", \"corpCls\", \"corpCode\", \"reprtCode\", \"rceptNo\", \"stockName\", \"updateDate\", \"bsnsYear\", \"quarter\"])[filterColumns]\n",
    "    print(df_train_set)\n",
    "    model = CoxPHFitter(penalizer=0.0001, l1_ratio=1)\n",
    "    model.fit(df_train_set, duration_col=\"period\", event_col=\"event\", fit_options=dict(step_size=0.2))\n",
    "\n",
    " //   f = io.BytesIO()\n",
    " //   joblib.dump(model, f)\n",
    " //   f.seek(0)\n",
    " //   s3.put_object(Bucket=\"penta-engine\", Key=f\"FinancialSheetsModel/{model_name}.pkl\", Body=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
