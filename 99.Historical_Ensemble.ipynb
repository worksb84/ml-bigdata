{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions._\n",
    "import scala.util.{Failure, Success, Try}\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "import java.time.LocalDateTime\n",
    "import java.time.LocalDate\n",
    "import java.time.format.DateTimeFormatter\n",
    "import java.time.temporal.ChronoUnit.DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateTimeFormatter = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\")\n",
    "def appName: String = LocalDateTime.now().format(dateTimeFormatter)\n",
    "def previousDay(minusDays: Long) = {\n",
    "    LocalDateTime.now().minusDays(minusDays).format(dateTimeFormatter).substring(0, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val appName = LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"))\n",
    "\n",
    "val spark = (\n",
    "    SparkSession\n",
    "    .builder()\n",
    "    .appName(appName)\n",
    "    .config(\"spark.cores.max\", 8)\n",
    "    .config(\"spark.executor.cores\", 8)\n",
    "    .config(\"spark.executor.memory\", \"36g\")\n",
    "    .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val mongoUrl = \"mongodb+srv://xxxxxxxxxxxxxxxxxxxxxx/\"\n",
    "val matchPipe = \"{ $match: { updateDate: { $gte: '20180101' } } }\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fsDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"ReportRiskPremiumCalcurate\")\n",
    "    .option(\"aggregation.pipeline\", matchPipe)\n",
    "    .load()\n",
    "    .drop(\"_id\", \"bsnsYear\", \"quarter\")\n",
    "    .withColumnRenamed(\"riskPremium\", \"FSRiskPremium\")\n",
    "    .where(!col(\"stockName\").like(\"%리츠%\") and \n",
    "           !col(\"stockName\").like(\"%베트남개발1%\") and \n",
    "           !col(\"stockName\").like(\"%상상인%\") and \n",
    "           !col(\"stockName\").like(\"%은행%\") and \n",
    "           !col(\"stockName\").like(\"%보험%\") and \n",
    "           !col(\"stockName\").like(\"%증권%\") and \n",
    "           !col(\"stockName\").like(\"%화재%\") and \n",
    "           !col(\"stockName\").like(\"%케이프%\") and \n",
    "           !col(\"stockName\").like(\"%CNH%\") and \n",
    "           !col(\"stockName\").like(\"%금융%\") and \n",
    "           !col(\"stockName\").like(\"%신한지주%\") and \n",
    "           !col(\"stockName\").like(\"%리드코프%\")\n",
    "          )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val nsDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"NewsRiskPremium\")\n",
    "    .load()\n",
    "    .drop(\"_id\", \"riskParagraph\", \"wholeParagraph\")\n",
    "    .withColumnRenamed(\"riskPremium\", \"NSRiskPremium\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val prDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"Price\")\n",
    "    .option(\"aggregation.pipeline\", matchPipe)\n",
    "    .load()\n",
    "    .select(\"stockCode\", \"updateDate\", \"classify\")\n",
    "    .withColumn(\"classify\", when(col(\"classify\") === \"KOSPI\", \"Y\").otherwise(\"K\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val hfDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"PriceRiskPremium\")\n",
    "    .option(\"aggregation.pipeline\", matchPipe)\n",
    "    .load()\n",
    "    .drop(\"_id\", \"stockFullName\")\n",
    "    .withColumnRenamed(\"riskPremium\", \"HFRiskPremium\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val indexDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"IndexComposition\")\n",
    "    .option(\"aggregation.pipeline\", matchPipe)\n",
    "    .load()\n",
    "    .select(\"updateDate\", \"rank\", \"index\", \"isuSrtCd\")\n",
    "    .withColumnRenamed(\"isuSrtCd\", \"stockCode\")\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val vixDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"KospiVolatilityCalcurate\")\n",
    "    .load()\n",
    "    .drop(\"_id\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val kosdaq150Df = indexDf.where(col(\"index\") === \"kosdaq_150\").withColumnRenamed(\"rank\", \"kosdaq150\").drop(\"rank\").drop(\"index\")\n",
    "val kospi200Df = indexDf.where(col(\"index\") === \"kospi_200\").withColumnRenamed(\"rank\", \"kospi200\").drop(\"rank\").drop(\"index\")\n",
    "val krx100Df = indexDf.where(col(\"index\") === \"krx_100\").withColumnRenamed(\"rank\", \"krx100\").drop(\"rank\").drop(\"index\")\n",
    "val krx300Df = indexDf.where(col(\"index\") === \"krx_300\").withColumnRenamed(\"rank\", \"krx300\").drop(\"rank\").drop(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val crDf = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"CreditLoanRate\")\n",
    "    .load()\n",
    "    .select(\"stockCode\", \"updateDate\", \"balanceRateLoan\")\n",
    "    .withColumn(\"balanceRateLoan\", col(\"balanceRateLoan\").cast(DoubleType))\n",
    "    .withColumn(\"stockCode\", lpad(col(\"stockCode\"), 6, \"0\"))\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "// root\n",
    "//  |-- FSPctRank: double (nullable = true)\n",
    "//  |-- VaRTF1: double (nullable = true)\n",
    "//  |-- VaRTF2: double (nullable = true)\n",
    "//  |-- basicReturn: double (nullable = true)\n",
    "//  |-- corpCls: string (nullable = true)\n",
    "//  |-- corpCode: string (nullable = true)\n",
    "//  |-- event: long (nullable = true)\n",
    "//  |-- expectedProfit: double (nullable = true)\n",
    "//  |-- expectedRisk: double (nullable = true)\n",
    "//  |-- grade: string (nullable = true)\n",
    "//  |-- loanAvailable: integer (nullable = true)\n",
    "//  |-- predict: long (nullable = true)\n",
    "//  |-- profitLoss: double (nullable = true)\n",
    "//  |-- rceptNo: string (nullable = true)\n",
    "//  |-- reprtCode: string (nullable = true)\n",
    "//  |-- FSRiskPremium: double (nullable = true)\n",
    "//  |-- stockCode: string (nullable = true)\n",
    "//  |-- stockName: string (nullable = true)\n",
    "//  |-- threshold: double (nullable = true)\n",
    "//  |-- updateDate: string (nullable = true)\n",
    "\n",
    "val ff = Window.partitionBy(\"stockCode\").orderBy(\"updateDate\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "val riskPremiumDfTemp = (\n",
    "    hfDf\n",
    "    .join(fsDf, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(nsDf, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(vixDf, Seq(\"updateDate\"), \"left\")\n",
    "    .join(prDf, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .withColumn(\"BDRiskPremium\", lit(0))\n",
    "    .withColumn(\"FNRiskPremium\", rand() * 0.001)\n",
    "    .withColumn(\"FSPctRank\", last(col(\"FSPctRank\"), true).over(ff))\n",
    "    .withColumn(\"VaRTF1\", last(col(\"VaRTF1\"), true).over(ff))\n",
    "    .withColumn(\"VaRTF2\", last(col(\"VaRTF2\"), true).over(ff))\n",
    "    .withColumn(\"basicReturn\", last(col(\"basicReturn\"), true).over(ff))\n",
    "    .withColumn(\"corpCls\", last(col(\"corpCls\"), true).over(ff))\n",
    "    .withColumn(\"corpCode\", last(col(\"corpCode\"), true).over(ff))\n",
    "    .withColumn(\"event\", last(col(\"event\"), true).over(ff))\n",
    "    .withColumn(\"expectedProfit\", last(col(\"expectedProfit\"), true).over(ff))\n",
    "    .withColumn(\"expectedRisk\", last(col(\"expectedRisk\"), true).over(ff))\n",
    "    .withColumn(\"grade\", last(col(\"grade\"), true).over(ff))\n",
    "    .withColumn(\"loanAvailable\", last(col(\"loanAvailable\"), true).over(ff))\n",
    "    .withColumn(\"predict\", last(col(\"predict\"), true).over(ff))\n",
    "    .withColumn(\"profitLoss\", last(col(\"profitLoss\"), true).over(ff))\n",
    "    .withColumn(\"rceptNo\", last(col(\"rceptNo\"), true).over(ff))\n",
    "    .withColumn(\"reprtCode\", last(col(\"reprtCode\"), true).over(ff))\n",
    "    .withColumn(\"FSRiskPremium\", last(col(\"FSRiskPremium\"), true).over(ff))\n",
    "    .withColumn(\"stockCode\", last(col(\"stockCode\"), true).over(ff))\n",
    "    .withColumn(\"stockName\", last(col(\"stockName\"), true).over(ff))\n",
    "    .withColumn(\"threshold\", last(col(\"threshold\"), true).over(ff))\n",
    "    .withColumn(\"BDRiskPremium\", last(col(\"BDRiskPremium\"), true).over(ff))\n",
    "    .withColumn(\"FNRiskPremium\", last(col(\"FNRiskPremium\"), true).over(ff))\n",
    "    .where(col(\"FSPctRank\").isNotNull)\n",
    "    .drop(\"corpCls\")\n",
    "    .withColumnRenamed(\"classify\", \"corpCls\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val riskPremiumDf = (\n",
    "    riskPremiumDfTemp\n",
    "    .withColumn(\"FSPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"FSRiskPremium\")))\n",
    "    .withColumn(\"HFPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"HFRiskPremium\")))\n",
    "    .withColumn(\"BDPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"BDRiskPremium\")))\n",
    "    .withColumn(\"FNPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"FNRiskPremium\")))\n",
    "    .withColumn(\"NSPctRank\", percent_rank().over(Window.partitionBy(\"updateDate\").orderBy(\"NSRiskPremium\")))\n",
    "    .withColumn(\"grade\", lit(\"D\"))\n",
    "    .withColumn(\"grade\", when(col(\"predict\") >= 1, lit(\"F\")).otherwise(col(\"grade\")))\n",
    "    .withColumn(\"grade\", when(col(\"FSPctRank\") <= 0.40, lit(\"C\")).otherwise(col(\"grade\")))\n",
    "    .withColumn(\"grade\", when(col(\"FSPctRank\") <= 0.20, lit(\"B\")).otherwise(col(\"grade\")))\n",
    "    .withColumn(\"grade\", when(col(\"FSPctRank\") <= 0.10, lit(\"A\")).otherwise(col(\"grade\")))\n",
    "    .withColumn(\"riskPremium\", col(\"FSPctRank\") + (col(\"BDPctRank\") * lit(0.0001)) + (col(\"HFPctRank\") * lit(0.0001)) + (col(\"FNPctRank\") * lit(0.0001)) + (col(\"NSPctRank\") * lit(0.0001)))\n",
    "    .withColumn(\"prevRiskPremium\", lag(col(\"riskPremium\"), 1).over(Window.partitionBy(\"stockCode\").orderBy(\"updateDate\")))\n",
    "    .withColumn(\"diffRiskPremium\", col(\"riskPremium\") - col(\"prevRiskPremium\"))\n",
    "    .where(col(\"stockName\").isNotNull)\n",
    "    .withColumn(\"score\", ((lit(1) - col(\"FSPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"FSScore\", ((lit(1) - col(\"FSPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"HFScore\", ((lit(1) - col(\"HFPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"BDScore\", ((lit(1) - col(\"BDPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"FNScore\", ((lit(1) - col(\"FNPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"NSScore\", ((lit(1) - col(\"NSPctRank\")) * 10000).cast(IntegerType))\n",
    "    .withColumn(\"ReRank\", row_number().over(Window.partitionBy(col(\"updateDate\")).orderBy(col(\"FSRiskPremium\"), col(\"VaRTF1\"))))\n",
    "    .withColumn(\"loanThreshold\", sum(when(col(\"grade\") === \"A\" or col(\"grade\") === \"B\" or col(\"grade\") === \"C\", 1).otherwise(0)).over(Window.partitionBy(col(\"updateDate\"))) * col(\"volatilityThreshold\"))\n",
    "    .withColumn(\"creditLoanAvailable\", when(col(\"score\") < col(\"loanThreshold\"), 1).otherwise(0))\n",
    "    .join(kosdaq150Df, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(kospi200Df, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(krx100Df, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .join(krx300Df, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .withColumn(\"fs\", struct(col(\"FSRiskPremium\").as(\"riskPremium\"), col(\"FSScore\").as(\"score\")))\n",
    "    .withColumn(\"hf\", struct(col(\"HFRiskPremium\").as(\"riskPremium\"), col(\"HFScore\").as(\"score\")))\n",
    "    .withColumn(\"bd\", struct(col(\"BDRiskPremium\").as(\"riskPremium\"), col(\"BDScore\").as(\"score\")))\n",
    "    .withColumn(\"fn\", struct(col(\"FNRiskPremium\").as(\"riskPremium\"), col(\"FNScore\").as(\"score\")))\n",
    "    .withColumn(\"ns\", struct(col(\"NSRiskPremium\").as(\"riskPremium\"), col(\"NSScore\").as(\"score\")))\n",
    "    .withColumn(\"detail\", struct(col(\"fs\"), col(\"hf\"), col(\"bd\"), col(\"fn\"), col(\"ns\")))\n",
    "    .withColumn(\"rank\", struct(col(\"ReRank\"), col(\"kosdaq150\"), col(\"kospi200\"), col(\"krx100\"), col(\"krx300\")))\n",
    "    .select(\"corpCls\", \"stockCode\", \"updateDate\", \"grade\", \"loanThreshold\", \"stockName\", \"riskPremium\", \"prevRiskPremium\", \"diffRiskPremium\", \"score\", \"detail\", \"rank\", \"loanAvailable\", \"creditLoanAvailable\", \"VaRTF1\", \"VaRTF2\", \"basicReturn\", \"expectedProfit\", \"expectedRisk\", \"profitLoss\")\n",
    "    .join(crDf, Seq(\"stockCode\", \"updateDate\"), \"left\")\n",
    "    .withColumn(\"balanceRateLoan\", last(col(\"balanceRateLoan\"), true).over(ff))\n",
    "    .na.fill(0)\n",
    "    )\n",
    "\n",
    "//     .withColumn(\"score\", col(\"ReRank\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(\n",
    "    riskPremiumDf\n",
    "    .write.format(\"mongodb\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"upsertDocument\", \"true\")\n",
    "    .option(\"idFieldList\", \"updateDate,stockCode\")\n",
    "    .option(\"spark.mongodb.read.connection.uri\", mongoUrl)\n",
    "    .option(\"spark.mongodb.write.connection.uri\", mongoUrl)\n",
    "    .option(\"database\", \"coreEngine\")\n",
    "    .option(\"collection\", \"RiskPremium\")\n",
    "    .save()\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
